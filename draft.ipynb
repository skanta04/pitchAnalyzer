{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Frequency Distribution imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Shreeya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch = \"Hi, my name is shreeya kantamsetty and I am rising sophomore. I am interested in machine learning and data science. I have expertise in web development such as angular, css, and html. \""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi',\n",
       " ',',\n",
       " 'my',\n",
       " 'name',\n",
       " 'is',\n",
       " 'shreeya',\n",
       " 'kantamsetty',\n",
       " 'and',\n",
       " 'I',\n",
       " 'am',\n",
       " 'rising',\n",
       " 'sophomore',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'data',\n",
       " 'science',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'expertise',\n",
       " 'in',\n",
       " 'web',\n",
       " 'development',\n",
       " 'such',\n",
       " 'as',\n",
       " 'angular',\n",
       " ',',\n",
       " 'css',\n",
       " ',',\n",
       " 'and',\n",
       " 'html',\n",
       " '.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_tokens = word_tokenize(pitch)\n",
    "pitch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words (words in the natural language that have very little meaning ) from the pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stopwords = stopwords.words('english')\n",
    "more_stopwords = ['Hi','hi','.',',']\n",
    "for word in more_stopwords:\n",
    "    all_stopwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pitch_tokens = [word for word in pitch_tokens if word not in all_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'i': 3, 'name': 1, 'shreeya': 1, 'kantamsetty': 1, 'rising': 1, 'sophomore': 1, 'interested': 1, 'machine': 1, 'learning': 1, 'data': 1, ...})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in filtered_pitch_tokens:\n",
    "    fdist[word.lower()]+= 1\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 1\n",
      "shreeya: 1\n",
      "kantamsetty: 1\n",
      "i: 3\n",
      "rising: 1\n",
      "sophomore: 1\n",
      "interested: 1\n",
      "machine: 1\n",
      "learning: 1\n",
      "data: 1\n",
      "science: 1\n",
      "expertise: 1\n",
      "web: 1\n",
      "development: 1\n",
      "angular: 1\n",
      "css: 1\n",
      "html: 1\n"
     ]
    }
   ],
   "source": [
    "for word, frequency in fdist.items():\n",
    "    print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
